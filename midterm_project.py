import streamlit as st
import pandas as pd
import json
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.figure_factory as ff

pd.DataFrame.iteritems = pd.DataFrame.items

def load_csv(csv_path, save = False):
	with pd.read_csv(csv_path, iterator=True) as reader:
		chunk_df = reader.get_chunk(10000)	
		chunk_df.sort_values(by='date', inplace = True)
		print(chunk_df['date'].iloc[0], chunk_df['date'].iloc[5000], chunk_df['date'].iloc[-1])
		
		if save:
			chunk_df.to_csv('/home/builder/Downloads/CMSE/gcrp_50K.csv', index=False)

	return chunk_df

def draw_hist_plot(x_val, y_val, df):

	if x_val in ['Browser Type','OS Type']:
		fig = plt.figure(figsize=(30, 10))
	else:	
		fig = plt.figure(figsize=(10, 4))

	# Set the style of the plot (optional)
	sns.set(style="whitegrid")

	# Create the histogram plot
	sns.barplot(x=x_val, y=y_val, data=df)

	# Add labels and a title
	plt.xlabel("Group")
	plt.ylabel('Revenue')
	plt.title('Revenue Distribution')

	st.write("Please choose options from top-left drop-down menu or zoom-in by selecting button on right top of figure for better visibility!")

	st.pyplot(fig, use_container_width = True)



if __name__=='__main__':

	st.title("Google analytics customer revenue estimation dashboard")
	st.caption("https://www.kaggle.com/c/ga-customer-revenue-prediction")
	st.caption("If dashboard becomes unresponsive. Please try to open it in incognito or private mode.")

	st.subheader("Introductory description of dashboard:")
	st.write("Dashboard allows better decision making for targeted marketing. It is designed for \
		officials working in domain of digital marketing facing challenges like understanding data better, \
		making informed decisions and most importantly identify potential buyers using 80/20 rule. In this \
		context, 80/20 rule states that 80% of revenue is generated by 20% percent of customers/mediums and purpose \
		of this dashboard is to hightlight this 20%. To achieve this goal in this dashboard, we will use Google online \
		store data, to demonstrate key insights after analysis of basic user behaviour and buying patterns from \
		online Google Merchandise Store.")

	path = 'gcrp_5K.csv'
	df = pd.read_csv(path)
	df.dropna(inplace = True)

	subset_data_array = []

	for id_ in range(len(df)):
		
		row_data = df.iloc[id_]
		channelGrouping = row_data['channelGrouping']
		date = row_data['date']
		fullVisitorid = row_data['fullVisitorId']
		social_eng_type = row_data['socialEngagementType']
		country = row_data['Country']

		totals = json.loads(row_data['totals'])
		
		if 'transactionRevenue' in totals.keys():
			total_splitted_data = [int(float(totals['transactionRevenue']))]
		else:
			total_splitted_data = [int(0.0)]

		if 'timeOnSite' in totals.keys():
			total_splitted_data.extend([int(float(totals['timeOnSite']))])
		else:
			total_splitted_data.extend([int(0.0)])

		device_data = json.loads(row_data['device'])
		device_splitted_data = [device_data['browser'],
							device_data['operatingSystem'], device_data['isMobile'],
							device_data['deviceCategory']]
		

		buffer_array = [channelGrouping, date, fullVisitorid, social_eng_type, country]
		buffer_array.extend(device_splitted_data)
		buffer_array.extend(total_splitted_data)
		subset_data_array.append(buffer_array)
	
	
	subset_data_nparray = np.array(subset_data_array)
	
	col_names = ['Channel Grouping','Date','VisitorId','Social Engagement Type',
						'Country', 'Browser Type','OS Type','Mobile', 'Device Type', 'Transaction Revenue', 'TimeOnSite']
	subset_df = pd.DataFrame(subset_data_array, columns=col_names)
	subset_df = pd.concat([subset_df, df[['lat', 'long']]], axis = 1)
	subset_df.dropna(inplace=True)

	
	st.subheader("Buyer density based on geographical locations.")
	st.write("As it is evident in map below, most dense regions of online visitors \
	are US, Canada, UK and European countries, etc. This information is vital for effective \
	Ads spending, focusing on online store visitors of these regions only and ignoring rest of \
	the traffic.")
	
	subset_df_map = subset_df.copy()
	min_value = -1
	max_value = 1
	random_latitude = np.random.uniform(min_value, max_value, len(subset_df_map))
	random_longitude = np.random.uniform(min_value, max_value, len(subset_df_map))
	
	subset_df_map['lat']+=random_latitude
	subset_df_map['long']+=random_longitude
	st.map(subset_df_map, latitude='lat', longitude='long', size='Transaction Revenue')

	selected_features = ['Channel Grouping','Social Engagement Type',
						'Browser Type','OS Type','Mobile', 'Device Type']

	hist_type = st.sidebar.selectbox('Buyer traits filter for Revenue: ', selected_features)
	grouped_data = subset_df.groupby(hist_type)['Transaction Revenue'].sum().reset_index()
	st.divider()
	
	st.subheader("Buyer traits based revenue distribution.")
	st.write("Following chart depicts proportion of mediums/devices/browsers/OS, etc which were used while making \
		purchases by customers. It shows clearly that Referral and Organic Search has generated \
		most revenue which should be our focus as per 80/20 rule. As per this set of data, we should \
		focus spending on generating organic search and referrals while ignoring rest of the mediums initially. Similar \
		approach should be followed for rest of the choices which can be explored using top-left drop-down menu. ")
	draw_hist_plot(x_val=hist_type, y_val='Transaction Revenue', df=grouped_data)
	st.divider()

	with st.sidebar:
		add_radio = st.radio("Choose filter for traffic analysis.",
			selected_features)
		grouped_data = subset_df.groupby(add_radio).size().reset_index()
		
		fig = px.bar(grouped_data, x=add_radio, y=0, labels={
                     add_radio: add_radio,
                     '0': "Online Traffic"})
		st.caption("Important stats regarding dataset.")
		st.write(subset_df[['TimeOnSite', 'Transaction Revenue']].describe())

		st.write('Top Revenue transactions: ')
		st.write(subset_df.sort_values(by='Transaction Revenue',ascending=False)[:5])

	
	st.subheader("Online store Traffic Analysis")
	st.caption("Please choose options from screen's top-left radio buttons or zoom-in \
				by selecting button on right top of figure for better visibility!")
	st.write("Following plots show high traffic mediums which are used to access online Google store, \
		browsers, whether store is visited on mobile phone or not, etc. Higher the traffic, higher \
		the odds of finding potential customer therefore, budget and other efforts should be focused \
		on ways which generate high online traffic i.e Organic Search, Chrome browser, desktop \
		devices, etc.")
	st.plotly_chart(fig, use_container_width=True)
	st.divider()
	
	st.subheader("Online Store Visitor buying behaviour.")
	st.write("Here interactive plot illustrates 80/20 rule, it is obvious that most of the online visits \
		do not result in a purchase however, few do, and they generate most of the revenue. In following graph, \
		size of the circle represents the generated revenue which shows that very few purchases generated millions \
		of dollars in revenue and it also highlights factors important in this process.")
	fig = px.scatter(
	    subset_df,
	    x="VisitorId",
	    y="Transaction Revenue",
	    size='TimeOnSite',
	    color="Channel Grouping",
	    color_continuous_scale="reds",
	)
	
	tab1, tab2 = st.tabs(["Streamlit theme (default)", "Plotly native theme"])
	with tab1:
	    st.plotly_chart(fig, theme="streamlit", use_container_width=True)
	with tab2:
	    st.plotly_chart(fig, theme=None, use_container_width=True)
	st.divider()

	fig = plt.figure(figsize=(10, 4))
	st.subheader("Why this dataset needs data analysis and modelling?")
	st.caption("Hint: Technically speaking, most of the purchases are made by outliers.")
	st.write("Credits to data analysis, it's obvious by boxplot of revenue that most of the generated revenue is by outlier data points \
		which reinforces our understanding of 80/20 rule to some extent. Data analysis is crucial for this dataset \
		because we need to get deeper insight about factors which drive this purchasing behaviour. Key takeaway for \
		marketing official here is to avoid mainstream marketing mediums and focus on ways which allow us to reach these outliers.")
	
	sns.boxplot(data=subset_df, x='Transaction Revenue')
	st.pyplot(fig)
	st.divider()
	
	st.subheader("Parallel Plot for Revenue")
	st.caption('Effective with white background!')
	st.write("Here parallel plot highlights key factor in generating revenue which is total time spent \
		on online store by user, higher the spent time higher the odds of revenue (darker lines). It suggests that we should \
		also spend and focus on user interface, user experience and other factors which can keep visitor engaged on site. \
		Very high values for spent time should be ignored (except few exceptions) as they likely represent data scrapping bots \
		in most cases, safe range is less than or equal to 2000.")

	fig = px.parallel_coordinates(subset_df[['Date', 'VisitorId','TimeOnSite', 'Transaction Revenue']], color="Transaction Revenue",color_continuous_scale=px.colors.diverging.Tealrose, color_continuous_midpoint=2)
	st.plotly_chart(fig)

	st.divider()
	
	st.subheader("Correlation between Time spent and Revenue")
	st.write("Finally, we demonstrate correlation between revenue and spent time. \
			Due to presence of large number of zeros, relation is not clear exactly \
			however it is evident that in specific range of spent time i.e <1500, most \
			of the purchases are observed. Furthurmore, an interesting observation here \
			is that it's likely that datapoints with large time spent but no purchases made \
			can represent data scraping bots not actual users which can allow us to ignore them \
			for Ads or restrict them.")
	fig = px.scatter(subset_df, x='TimeOnSite', y='Transaction Revenue')
	st.plotly_chart(fig)

